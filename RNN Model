from keras.datasets import imdb
from keras.preprocessing.text import Tokenizer
from keras.utils import pad_sequences
from keras import Sequential
from keras.layers import Dense,SimpleRNN,Embedding,Flatten

// Loading keras imdb
(X_train,y_train),(X_test,y_test) = imdb.load_data()

// Padding the vector
X_train = pad_sequences(X_train,padding='post',maxlen=100)
X_test = pad_sequences(X_test,padding='post',maxlen=100)

X_train.shape

// Embedding, Modelling RNN and Compiling the Model
model = Sequential()
model.add(Embedding(10000,2,input_length=100))
model.add(SimpleRNN(32,return_sequences=False))
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])
model.summary()

//Training the Model
model.fit(X_train, y_train,epochs=5,validation_data=(X_test,y_test))

